{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import skrvm #https://github.com/JamesRitchie/scikit-rvm\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "news = datasets.fetch_20newsgroups\n",
    "news_train = news(subset='train', categories= ['comp.os.ms-windows.misc', 'comp.sys.mac.hardware'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#load Windows & Mac Training Data\n",
    "newsgroups_train = datasets.fetch_20newsgroups(subset='train', categories = ['comp.os.ms-windows.misc', 'comp.sys.mac.hardware'])\n",
    "#Load Windows & Mac Target Data\n",
    "news_train_target = news(subset='train', categories= ['comp.os.ms-windows.misc', 'comp.sys.mac.hardware']).target\n",
    "#TDIF\n",
    "vectorizer = TfidfVectorizer()\n",
    "newsgroups_train.data = vectorizer.fit_transform(newsgroups_train.data)\n",
    "#Turn to dense matrix\n",
    "news_train_data = newsgroups_train.data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from https://github.com/JamesRitchie/scikit-rvm\n",
    "\n",
    "\"\"\"Relevance Vector Machine classes for regression and classification.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\n",
    "from sklearn.metrics.pairwise import (\n",
    "    linear_kernel,\n",
    "    rbf_kernel,\n",
    "    polynomial_kernel\n",
    ")\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.utils.validation import check_X_y\n",
    "\n",
    "\n",
    "class BaseRVM(BaseEstimator):\n",
    "\n",
    "    \"\"\"Base Relevance Vector Machine class.\n",
    "    Implementation of Mike Tipping's Relevance Vector Machine using the\n",
    "    scikit-learn API. Add a posterior over weights method and a predict\n",
    "    in subclass to use for classification or regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        coef1=None,\n",
    "        coef0=0.0,\n",
    "        n_iter=3000,\n",
    "        tol=1e-3,\n",
    "        alpha=1e-6,\n",
    "        threshold_alpha=1e9,\n",
    "        beta=1.e-6,\n",
    "        beta_fixed=False,\n",
    "        bias_used=True,\n",
    "        verbose=False\n",
    "    ):\n",
    "        \"\"\"Copy params to object properties, no validation.\"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.coef1 = coef1\n",
    "        self.coef0 = coef0\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.alpha = alpha\n",
    "        self.threshold_alpha = threshold_alpha\n",
    "        self.beta = beta\n",
    "        self.beta_fixed = beta_fixed\n",
    "        self.bias_used = bias_used\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Return parameters as a dictionary.\"\"\"\n",
    "        params = {\n",
    "            'kernel': self.kernel,\n",
    "            'degree': self.degree,\n",
    "            'coef1': self.coef1,\n",
    "            'coef0': self.coef0,\n",
    "            'n_iter': self.n_iter,\n",
    "            'tol': self.tol,\n",
    "            'alpha': self.alpha,\n",
    "            'threshold_alpha': self.threshold_alpha,\n",
    "            'beta': self.beta,\n",
    "            'beta_fixed': self.beta_fixed,\n",
    "            'bias_used': self.bias_used,\n",
    "            'verbose': self.verbose\n",
    "        }\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        \"\"\"Set parameters using kwargs.\"\"\"\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def _apply_kernel(self, x, y):\n",
    "        \"\"\"Apply the selected kernel function to the data.\"\"\"\n",
    "        if self.kernel == 'linear':\n",
    "            phi = linear_kernel(x, y)\n",
    "        elif self.kernel == 'rbf':\n",
    "            phi = rbf_kernel(x, y, self.coef1)\n",
    "        elif self.kernel == 'poly':\n",
    "            phi = polynomial_kernel(x, y, self.degree, self.coef1, self.coef0)\n",
    "        elif callable(self.kernel):\n",
    "            phi = self.kernel(x, y)\n",
    "            if len(phi.shape) != 2:\n",
    "                raise ValueError(\n",
    "                    \"Custom kernel function did not return 2D matrix\"\n",
    "                )\n",
    "            if phi.shape[0] != x.shape[0]:\n",
    "                raise ValueError(\n",
    "                    \"Custom kernel function did not return matrix with rows\"\n",
    "                    \" equal to number of data points.\"\"\"\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\"Kernel selection is invalid.\")\n",
    "\n",
    "        if self.bias_used:\n",
    "            phi = np.append(phi, np.ones((phi.shape[0], 1)), axis=1)\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def _prune(self):\n",
    "        \"\"\"Remove basis functions based on alpha values.\"\"\"\n",
    "        keep_alpha = self.alpha_ < self.threshold_alpha\n",
    "\n",
    "        if not np.any(keep_alpha):\n",
    "            keep_alpha[0] = True\n",
    "            if self.bias_used:\n",
    "                keep_alpha[-1] = True\n",
    "\n",
    "        if self.bias_used:\n",
    "            if not keep_alpha[-1]:\n",
    "                self.bias_used = False\n",
    "            self.relevance_ = self.relevance_[keep_alpha[:-1]]\n",
    "        else:\n",
    "            self.relevance_ = self.relevance_[keep_alpha]\n",
    "\n",
    "        self.alpha_ = self.alpha_[keep_alpha]\n",
    "        self.alpha_old = self.alpha_old[keep_alpha]\n",
    "        self.gamma = self.gamma[keep_alpha]\n",
    "        self.phi = self.phi[:, keep_alpha]\n",
    "        self.sigma_ = self.sigma_[np.ix_(keep_alpha, keep_alpha)]\n",
    "        self.m_ = self.m_[keep_alpha]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the RVR to the training data.\"\"\"\n",
    "        X, y = check_X_y(X, y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.phi = self._apply_kernel(X, X)\n",
    "\n",
    "        n_basis_functions = self.phi.shape[1]\n",
    "\n",
    "        self.relevance_ = X\n",
    "        self.y = y\n",
    "\n",
    "        self.alpha_ = self.alpha * np.ones(n_basis_functions)\n",
    "        self.beta_ = self.beta\n",
    "\n",
    "        self.m_ = np.zeros(n_basis_functions)\n",
    "\n",
    "        self.alpha_old = self.alpha_\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            self._posterior()\n",
    "\n",
    "            self.gamma = 1 - self.alpha_*np.diag(self.sigma_)\n",
    "            self.alpha_ = self.gamma/(self.m_ ** 2)\n",
    "\n",
    "            if not self.beta_fixed:\n",
    "                self.beta_ = (n_samples - np.sum(self.gamma))/(\n",
    "                    np.sum((y - np.dot(self.phi, self.m_)) ** 2))\n",
    "\n",
    "            self._prune()\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Iteration: {}\".format(i))\n",
    "                print(\"Alpha: {}\".format(self.alpha_))\n",
    "                print(\"Beta: {}\".format(self.beta_))\n",
    "                print(\"Gamma: {}\".format(self.gamma))\n",
    "                print(\"m: {}\".format(self.m_))\n",
    "                print(\"Relevance Vectors: {}\".format(self.relevance_.shape[0]))\n",
    "                print()\n",
    "\n",
    "            delta = np.amax(np.absolute(self.alpha_ - self.alpha_old))\n",
    "\n",
    "            if delta < self.tol and i > 1:\n",
    "                break\n",
    "\n",
    "            self.alpha_old = self.alpha_\n",
    "\n",
    "        if self.bias_used:\n",
    "            self.bias = self.m_[-1]\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "class RVR(BaseRVM, RegressorMixin):\n",
    "\n",
    "    \"\"\"Relevance Vector Machine Regression.\n",
    "    Implementation of Mike Tipping's Relevance Vector Machine for regression\n",
    "    using the scikit-learn API.\n",
    "    \"\"\"\n",
    "\n",
    "    def _posterior(self):\n",
    "        \"\"\"Compute the posterior distriubtion over weights.\"\"\"\n",
    "        i_s = np.diag(self.alpha_) + self.beta_ * np.dot(self.phi.T, self.phi)\n",
    "        self.sigma_ = np.linalg.inv(i_s)\n",
    "        self.m_ = self.beta_ * np.dot(self.sigma_, np.dot(self.phi.T, self.y))\n",
    "\n",
    "    def predict(self, X, eval_MSE=False):\n",
    "        \"\"\"Evaluate the RVR model at x.\"\"\"\n",
    "        phi = self._apply_kernel(X, self.relevance_)\n",
    "\n",
    "        y = np.dot(phi, self.m_)\n",
    "\n",
    "        if eval_MSE:\n",
    "            MSE = (1/self.beta_) + np.dot(phi, np.dot(self.sigma_, phi.T))\n",
    "            return y, MSE[:, 0]\n",
    "        else:\n",
    "            return y\n",
    "\n",
    "\n",
    "class RVC(BaseRVM, ClassifierMixin):\n",
    "\n",
    "    \"\"\"Relevance Vector Machine Classification.\n",
    "    Implementation of Mike Tipping's Relevance Vector Machine for\n",
    "    classification using the scikit-learn API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iter_posterior=50, **kwargs):\n",
    "        \"\"\"Copy params to object properties, no validation.\"\"\"\n",
    "        self.n_iter_posterior = n_iter_posterior\n",
    "        super(RVC, self).__init__(**kwargs)\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Return parameters as a dictionary.\"\"\"\n",
    "        params = super(RVC, self).get_params(deep=deep)\n",
    "        params['n_iter_posterior'] = self.n_iter_posterior\n",
    "        return params\n",
    "\n",
    "    def _classify(self, m, phi):\n",
    "        return expit(np.dot(phi, m))\n",
    "\n",
    "    def _log_posterior(self, m, alpha, phi, t):\n",
    "\n",
    "        y = self._classify(m, phi)\n",
    "\n",
    "        log_p = -1 * (np.sum(np.log(y[t == 1]+.00000001), 0) +\n",
    "                      np.sum(np.log(1-y[t == 0]+.00000001), 0))\n",
    "        log_p = log_p + 0.5*np.dot(m.T, np.dot(np.diag(alpha), m))\n",
    "\n",
    "        jacobian = np.dot(np.diag(alpha), m) - np.dot(phi.T, (t-y))\n",
    "\n",
    "        return log_p, jacobian\n",
    "\n",
    "    def _hessian(self, m, alpha, phi, t):\n",
    "        y = self._classify(m, phi)\n",
    "        B = np.diag(y*(1-y))\n",
    "        return np.diag(alpha) + np.dot(phi.T, np.dot(B, phi))\n",
    "\n",
    "    def _posterior(self):\n",
    "        result = minimize(\n",
    "            fun=self._log_posterior,\n",
    "            hess=self._hessian,\n",
    "            x0=self.m_,\n",
    "            args=(self.alpha_, self.phi, self.t),\n",
    "            method='Newton-CG',\n",
    "            jac=True,\n",
    "            options={\n",
    "                'maxiter': self.n_iter_posterior\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.m_ = result.x\n",
    "        self.sigma_ = np.linalg.inv(\n",
    "            self._hessian(self.m_, self.alpha_, self.phi, self.t)\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Check target values and fit model.\"\"\"\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_classes = len(self.classes_)\n",
    "\n",
    "        if n_classes < 2:\n",
    "            raise ValueError(\"Need 2 or more classes.\")\n",
    "        elif n_classes == 2:\n",
    "            self.t = np.zeros(y.shape)\n",
    "            self.t[y == self.classes_[1]] = 1\n",
    "            return super(RVC, self).fit(X, self.t)\n",
    "        else:\n",
    "            self.multi_ = None\n",
    "            self.multi_ = OneVsOneClassifier(self)\n",
    "            self.multi_.fit(X, y)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return an array of class probabilities.\"\"\"\n",
    "        phi = self._apply_kernel(X, self.relevance_)\n",
    "        y = self._classify(self.m_, phi)\n",
    "        return np.column_stack((1-y, y))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return an array of classes for each input.\"\"\"\n",
    "        if len(self.classes_) == 2:\n",
    "            y = self.predict_proba(X)\n",
    "            res = np.empty(y.shape[0], dtype=self.classes_.dtype)\n",
    "            res[y[:, 1] <= 0.5] = self.classes_[0]\n",
    "            res[y[:, 1] >= 0.5] = self.classes_[1]\n",
    "            return res\n",
    "        else:\n",
    "            return self.multi_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Catherine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:462: DeprecationWarning: Passing 'None' to parameter 'accept_sparse' in methods check_array and check_X_y is deprecated in version 0.19 and will be removed in 0.21. Use 'accept_sparse=False'  instead.\n",
      "  \" instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       591\n",
      "           1       0.80      0.74      0.77       578\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1169\n",
      "   macro avg       0.78      0.78      0.78      1169\n",
      "weighted avg       0.78      0.78      0.78      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "clf = RVC()\n",
    "#fit RVM\n",
    "clf.fit(news_train_data, news_train_target)\n",
    "RVC(alpha=1e-06, beta=1e-06, beta_fixed=False, bias_used=False, coef0=0.0,coef1=None, degree=3, kernel='linear', n_iter=3000, n_iter_posterior=50,threshold_alpha=1000000000.0, tol=0.001, verbose=False)\n",
    "\n",
    "print(classification_report(news_train_target,rvm.predict(news_train_data)))\n",
    "\n",
    "\n",
    "#PLOT IF LOWER DIMENSION\n",
    "# n_grid = 500\n",
    "# max_x      = np.max(news_train_data,axis = 0)\n",
    "# min_x      = np.min(news_train_data,axis = 0)\n",
    "# X1         = np.linspace(min_x[0],max_x[0],n_grid)\n",
    "# X2         = np.linspace(min_x[1],max_x[1],n_grid)\n",
    "# n_grid = 500\n",
    "# max_x      = np.max(news_train_data,axis = 0)\n",
    "# min_x      = np.min(news_train_data,axis = 0)\n",
    "# X1         = np.linspace(min_x[0],max_x[0],n_grid)\n",
    "# X2         = np.linspace(min_x[1],max_x[1],n_grid)\n",
    "# x1,x2      = np.meshgrid(X1,X2)\n",
    "# Xgrid      = np.zeros([n_grid**2,2])\n",
    "# Xgrid[:,0] = np.reshape(x1,(n_grid**2,))\n",
    "# Xgrid[:,1] = np.reshape(x2,(n_grid**2,))\n",
    "\n",
    "# rv_grid = rvm.predict_proba(Xgrid)[:,1]\n",
    "# models  = [rv_grid]\n",
    "# model_names = [\"RVC\"]\n",
    "               \n",
    "               \n",
    "# for model, model_name in zip(models, model_names):\n",
    "#     plt.figure(figsize = (12,8))\n",
    "#     plt.contourf(X1,X2,np.reshape(model,(n_grid,n_grid)),\n",
    "#                        cmap=\"coolwarm\",\n",
    "#                        figsize = (10,16))\n",
    "#     plt.colorbar()\n",
    "#     plt.plot(news_train_data[news_train_target==0,0],news_train_data[news_train_target==0,1],\"bo\", markersize = 4)\n",
    "#     plt.plot(news_train_data[news_train_target==1,0],news_train_data[news_train_target==1,1],\"ro\", markersize = 4)\n",
    "#     # plot 'relevant' vectors\n",
    "#     svrv = None\n",
    "#     point_label = None\n",
    "#     svrv = rvm.relevant_vectors_[0]\n",
    "#     point_label = \"relevant vecs\"\n",
    "#     plt.plot(svrv[:,0],svrv[:,1],'co',markersize=8,label=point_label)\n",
    "#     plt.plot()\n",
    "#     title = model_name\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel(\"x1\")\n",
    "#     plt.ylabel(\"x2\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
